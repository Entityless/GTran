#Copyright 2018 Husky Data Lab, CUHK
#Authors: Hongzhi Chen

#ini file for example
#new line to end this ini

[HDFS]
HDFS_HOST_ADDRESS = master      #the hostname of hdfs name node
HDFS_PORT = 9000		        #the port of HDFS
HDFS_PORT = 9000
HDFS_INPUT_PATH = /aaron/DBpedia/DBpedia_gquery/
HDFS_INDEX_PATH = /aaron/DBpedia/DBpedia_gquery/index/
HDFS_VTX_SUBFOLDER = /aaron/DBpedia/DBpedia_gquery/vertices/
HDFS_VP_SUBFOLDER = /aaron/DBpedia/DBpedia_gquery/vtx_property/
HDFS_EP_SUBFOLDER = /aaron/DBpedia/DBpedia_gquery/edge_property/
HDFS_OUTPUT_PATH = /aaron/DBpedia/DBpedia_gquery/output/


[SYSTEM]
ISOLATION_LEVEL = SERIALIZABLE  # i.e., SERIALIZABLE or SNAPSHOT
NUM_THREADS = 10                # num of local computing threads
NUM_GC_CONSUMER = 4             # num of threads to execute GC
NUM_PARSER_THREADS = 2          # num of threads to process query parser, suggested value: 1 or 2
VTX_P_KV_SZ_GB = 2              # the size of KVS allocated for VTX Property, unit in #GB
EDGE_P_KV_SZ_GB = 6             # the size of KVS allocated for EDGE Property, unit in #GB
PER_SEND_BUF_SZ_MB = 2          # the size of send-buff for each thread, unit in #MB
PER_RECV_BUF_SZ_MB = 64         # the size of recv-buff for each worker, unit in #MB
VE_ROW_POOL_SIZE = 10000000     # the capacity of ConcurrentMemPool<VertexEdgeRow> in data store
VP_ROW_POOL_SIZE = 10000000     # the capacity of ConcurrentMemPool<VertexPropertyRow> in data store 
EP_ROW_POOL_SIZE = 10000000     # the capacity of ConcurrentMemPool<EdgePropertyRow> in data store
V_MVCC_POOL_SIZE = 20000000     # the capacity of ConcurrentMemPool<VertexMVCCItem> in data store
E_MVCC_POOL_SIZE = 20000000     # the capacity of ConcurrentMemPool<EdgeMVCCItem> in data store
VP_MVCC_POOL_SIZE = 30000000    # the capacity of ConcurrentMemPool<VPropertyMVCCItem> in data store
EP_MVCC_POOL_SIZE = 30000000    # the capacity of ConcurrentMemPool<EPropertyMVCCItem> in data store
PREDICT_CONTAINER_USAGE = true  # to output the prediction of the size of above ConcurrentMemPools, please do not set to false unless you know what you do 
TRX_TABLE_SZ_MB = 1024          # the size of TransactionStatusTable allocated on each worker
USE_RDMA = true                 # if enable RDMA, set false to use TCP for commun
ENABLE_MEM_POOL_UTILIZATION_RECORD = true  # to set if report the mem pool util during GC 
ENABLE_CACHE = true             #if enable cache in experts of transaction processing 
ENABLE_CORE_BIND = true         #if enable core-bind, see more details in our Grasper proj
ENABLE_EXPERT_DIVISION = true   #if enable expert division for logical thread regions, only useful when core-bind is on.
ENABLE_STEP_REORDER = true      #if enable query-step reorder for query optimization
ENABLE_INDEXING = true          #if enable index construction
ENABLE_STEALING = true          #if enable index construction
ENABLE_GARBAGE_COLLECT = true   #if enable GC, please do not set to false unless you know what you do
ENABLE_OPT_PREREAD = true       #if enable OPT(pre-read) in our transaction processing protocol, please do not set to false unless you know what you do
ENABLE_OPT_VALIDATION = true    #if enable OPT(optimistic-validation) in our transaction processing protocol, please do not set to false unless you know what you do
MAX_MSG_SIZE = 524288           #(bytes), the upper-bound of message size for splitting
SNAPSHOT_PATH = /home/yanda/tmp/gq_snapshot # the local path to store the graph snapshot on disk, to avoid repeatedly data loading when reboot the system.

[GC]
#TODO(Aaron), fill in the annotations for the below variables
ERASE_V_T_THRESHOLD = 100
ERASE_OUTE_T_THRESHOLD = 200
ERASE_INE_T_THRESHOLD = 200
VMVCC_GC_T_THRESHOLD = 200
VPMVCC_GC_T_THRESHOLD = 200
EPMVCC_GC_T_THRESHOLD = 200
EMVCC_GC_T_THRESHOLD = 200
TOPO_ROW_GC_T_THRESHOLD = 200
TOPO_ROW_DEFRAG_T_THRESHOLD = 200
VP_ROW_GC_T_THRESHOLD = 200
VP_ROW_DEFRAG_T_THRESHOLD = 200
EP_ROW_GC_T_THRESHOLD = 200
EP_ROW_DEFRAG_T_THRESHOLD = 200
TOPO_INDEX_GC_RATIO = 50
PROP_INDEX_GC_RATIO = 20
PROP_INDEX_GC_T_THRESHOLD = 10
RCT_GC_T_THRESHOLD = 10
